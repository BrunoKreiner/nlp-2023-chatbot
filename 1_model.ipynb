{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-2.12.0-py3-none-any.whl (474 kB)\n",
      "     -------------------------------------- 474.6/474.6 kB 6.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pandas in c:\\users\\shwet\\anaconda3\\lib\\site-packages (from datasets) (2.0.1)\n",
      "Collecting responses<0.19\n",
      "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\shwet\\anaconda3\\lib\\site-packages (from datasets) (4.64.1)\n",
      "Collecting xxhash\n",
      "  Downloading xxhash-3.2.0-cp39-cp39-win_amd64.whl (30 kB)\n",
      "Collecting multiprocess\n",
      "  Downloading multiprocess-0.70.14-py39-none-any.whl (132 kB)\n",
      "     ---------------------------------------- 132.9/132.9 kB ? eta 0:00:00\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in c:\\users\\shwet\\anaconda3\\lib\\site-packages (from datasets) (2022.7.1)\n",
      "Collecting pyarrow>=8.0.0\n",
      "  Downloading pyarrow-12.0.0-cp39-cp39-win_amd64.whl (21.5 MB)\n",
      "     --------------------------------------- 21.5/21.5 MB 19.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\shwet\\anaconda3\\lib\\site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in c:\\users\\shwet\\anaconda3\\lib\\site-packages (from datasets) (0.15.1)\n",
      "Collecting aiohttp\n",
      "  Downloading aiohttp-3.8.4-cp39-cp39-win_amd64.whl (323 kB)\n",
      "     ---------------------------------------- 323.6/323.6 kB ? eta 0:00:00\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in c:\\users\\shwet\\anaconda3\\lib\\site-packages (from datasets) (0.3.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\shwet\\anaconda3\\lib\\site-packages (from datasets) (1.21.5)\n",
      "Requirement already satisfied: packaging in c:\\users\\shwet\\anaconda3\\lib\\site-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\shwet\\anaconda3\\lib\\site-packages (from datasets) (2.28.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\shwet\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.3.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\shwet\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.6.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\shwet\\anaconda3\\lib\\site-packages (from packaging->datasets) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\shwet\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shwet\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\shwet\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shwet\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (2022.9.14)\n",
      "Requirement already satisfied: colorama in c:\\users\\shwet\\anaconda3\\lib\\site-packages (from tqdm>=4.62.1->datasets) (0.4.5)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\shwet\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (21.4.0)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.3.3-cp39-cp39-win_amd64.whl (34 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.9.2-cp39-cp39-win_amd64.whl (61 kB)\n",
      "     ---------------------------------------- 61.7/61.7 kB ? eta 0:00:00\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.4-cp39-cp39-win_amd64.whl (28 kB)\n",
      "Collecting dill<0.3.7,>=0.3.0\n",
      "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
      "     ---------------------------------------- 110.5/110.5 kB ? eta 0:00:00\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\shwet\\anaconda3\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\shwet\\anaconda3\\lib\\site-packages (from pandas->datasets) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\shwet\\anaconda3\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\shwet\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Installing collected packages: xxhash, pyarrow, multidict, frozenlist, dill, async-timeout, yarl, responses, multiprocess, aiosignal, aiohttp, datasets\n",
      "  Attempting uninstall: dill\n",
      "    Found existing installation: dill 0.3.4\n",
      "    Uninstalling dill-0.3.4:\n",
      "      Successfully uninstalled dill-0.3.4\n",
      "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 datasets-2.12.0 dill-0.3.6 frozenlist-1.3.3 multidict-6.0.4 multiprocess-0.70.14 pyarrow-12.0.0 responses-0.18.0 xxhash-3.2.0 yarl-1.9.2\n"
     ]
    }
   ],
   "source": [
    "#!pip install transformers\n",
    "#!pip install huggingface_hub\n",
    "#!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import load_dataset, load_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bc054628b3142718fa38b3483797417",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97800ef0cee14f21aa899fb8d99d411b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/5.36k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47191bf96664467fbec703abcd76df02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/2.99k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c15e8caa083486b8b9110b43fe9058e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/8.41k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset piqa/plain_text to C:/Users/shwet/.cache/huggingface/datasets/piqa/plain_text/1.1.0/6c611c1a9bf220943c4174e117d3b660859665baf1d43156230116185312d011...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eda91ed18696413396deaeae22fd1908",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7db169f26dbf40beb45b09ef5515fbfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.82M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecc093dc7f654acc82e5ae9d907203da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/815k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd014cba58e04a08ba0edd719136971c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e14d5d7449094e339bd89ca3f2589025",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/16113 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07821aad95c74a64a1e7b4ac3a6794bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/3084 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88a9e282099f454d92d470c955766a2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/1838 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset piqa downloaded and prepared to C:/Users/shwet/.cache/huggingface/datasets/piqa/plain_text/1.1.0/6c611c1a9bf220943c4174e117d3b660859665baf1d43156230116185312d011. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99bc04918903432aa92bd00595128d3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datasets = load_dataset(\"piqa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import ClassLabel, Sequence\n",
    "import random\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def show_random_elements(dataset, num_examples=10):\n",
    "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset)-1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset)-1)\n",
    "        picks.append(pick)\n",
    "    \n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    for column, typ in dataset.features.items():\n",
    "        if isinstance(typ, ClassLabel):\n",
    "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
    "        elif isinstance(typ, Sequence) and isinstance(typ.feature, ClassLabel):\n",
    "            df[column] = df[column].transform(lambda x: [typ.feature.names[i] for i in x])\n",
    "    display(HTML(df.to_html()))\n",
    "\n",
    "def to_df(dataset, num_examples=10):\n",
    "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset)-1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset)-1)\n",
    "        picks.append(pick)\n",
    "    \n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    for column, typ in dataset.features.items():\n",
    "        if isinstance(typ, ClassLabel):\n",
    "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
    "        elif isinstance(typ, Sequence) and isinstance(typ.feature, ClassLabel):\n",
    "            df[column] = df[column].transform(lambda x: [typ.feature.names[i] for i in x])\n",
    "    display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>goal</th>\n",
       "      <th>sol1</th>\n",
       "      <th>sol2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How to thicken tomato sauce without changing the flavor?</td>\n",
       "      <td>Once the tomato sauce has come together, reduce it by increasing the heat and leaving the lid off the pot until it is about one fifth less</td>\n",
       "      <td>Before the tomato sauce has come together, reduce it by lower the heat and leaving the lid on the pot until it is about one fifth less</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How to make Chocolate Mounds Candy bar Ice cream at home without an Ice cream Freezer.</td>\n",
       "      <td>In a medium mixing bowl combine 4 cups chilled whipping cream, 14 oz. can sweetened condensed milk, and 1 16 ounce can chocolate flavored syrup (Like Hershey's).  Beat with an electric mixer until soft Peaks form.  Fold in 3/4 cup Mounds Candy Bars (coarsely chopped) and 1/4 cup shredded Coconut.  Transfer mixture to 8x8x2 inch baking pan.  Freeze about 8 hours until firm. Serve any time after 8 hours freeze.</td>\n",
       "      <td>In a medium mixing bowl combine 4 cups chilled whipping cream, 14 oz. can sweetened condensed milk, and 1 16 ounce can chocolate flavored syrup (Like Hershey's).  Beat with an electric mixer until soft Peaks form.  Fold in 3/4 cup Mounds Candy Bars (coarsely chopped) and 1/4 cup shredded Coconut Palm leaves.  Transfer mixture to 8x8x2 inch baking pan.  Freeze about 8 hours until firm. Serve any time after 8 hours freeze.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>To dissolve salt in water,</td>\n",
       "      <td>add the salt to room temperature water in a cup and stir gently with a spoon until dissolved.</td>\n",
       "      <td>add the salt to freezing water in a cup and stir gently with a spoon until dissolved.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Remove masking tape without leaving residue.</td>\n",
       "      <td>Warm first with lighter.</td>\n",
       "      <td>Warm first with blow dryer.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>how do you remember someone who's died right after they die?</td>\n",
       "      <td>have a cremation for them.</td>\n",
       "      <td>have a memorial for them.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>How can you improvise a water sprayer for your hose at home?</td>\n",
       "      <td>Place a water or soda bottle on the end of your hose and duct tape it in place, then poke several holes in the bottle (strategically) to point and spray your hose.</td>\n",
       "      <td>Place a water or soda bottle on the shut off valve of your hose and duct tape it in place, then poke several holes in the bottle (strategically) to point and spray your hose.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>To get router table to make curves on the corner of wood.</td>\n",
       "      <td>Use a corner radius router jig.</td>\n",
       "      <td>Use a rounded piece of wood as template.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>How do I mop the floors?</td>\n",
       "      <td>Spread a little cleaner and water mixture onto the floor and mop it all around</td>\n",
       "      <td>Spread a little water and oil mixture into the floor and mop it all around</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>To attach the shelves to the back of the cabinet</td>\n",
       "      <td>Make sure the shelves have a place to rest on and use a soldering iron to attach everything</td>\n",
       "      <td>Make sure the shelves have a place to rest on and use a nail gun to attach everything</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>How do I spray with polyurethane?</td>\n",
       "      <td>Polyurethane comes in spray paint bottles. After purchasing a bottle shake it and spray it about a foot away from the surface and let it dry according to the instructions on the bottle before repeating.</td>\n",
       "      <td>Polyurethane comes in spray paint bottles. After purchasing a bottle shake it and spray it about 6 feet away from the surface and let it dry according to the instructions on the bottle before repeating.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_elements(datasets[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'goal': \"When boiling butter, when it's ready, you can\",\n",
       " 'sol1': 'Pour it onto a plate',\n",
       " 'sol2': 'Pour it into a jar',\n",
       " 'label': 1}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[\"train\"][0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "model_checkpoint = \"gpt2\"\n",
    "batch_size = 16   \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2Model, Trainer, TrainingArguments\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "\n",
    "model = GPT2Model.from_pretrained(\"gpt2\")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./gpt2\", #The output directory\n",
    "    overwrite_output_dir=True, #overwrite the content of the output directory\n",
    "    num_train_epochs=3, # number of training epochs\n",
    "    per_device_train_batch_size=32, # batch size for training\n",
    "    per_device_eval_batch_size=64,  # batch size for evaluation\n",
    "    eval_steps = 400, # Number of update steps between two evaluations.\n",
    "    save_steps=800, # after # steps model is saved\n",
    "    warmup_steps=500,# number of warmup steps for learning rate scheduler\n",
    "    )\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    prediction_loss_only=True,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
